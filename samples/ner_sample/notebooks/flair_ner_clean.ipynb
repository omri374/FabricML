{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Named Entity Recognition using Flair on CONLL-2003\n",
    "## Experiment description\n",
    "This notebook contains a ML fabric flow for Named Entity Recognition\n",
    "using the [flair NLP package](https://github.com/flairNLP/flair/)\n",
    "\n",
    "Note: This example uses the data objects already implemented in the ner_sample Python package. There's an [additional notebook with full implementations](flair_ner.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import flair\n",
    "import requests\n",
    "import torch\n",
    "from flair.data import Corpus, Sentence\n",
    "from flair.datasets import CONLL_03\n",
    "from flair.embeddings import TokenEmbeddings, WordEmbeddings, StackedEmbeddings, PooledFlairEmbeddings\n",
    "from flair.models import SequenceTagger\n",
    "from flair.trainers import ModelTrainer\n",
    "from seqeval.metrics import f1_score, accuracy_score\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from ner_sample import ExperimentRunner\n",
    "from ner_sample.data import ConllDataLoader\n",
    "from ner_sample.evaluation import NEREvaluator, NEREvaluationMetrics\n",
    "from ner_sample.experimentation import MlflowExperimentation\n",
    "from ner_sample.models import BaseModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "Download (if missing) the Conll-2003 dataset from Github and load it into memory using a flair Corpus object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = ConllDataLoader(dataset_name = \"conll_03\", dataset_version=\"1\")\n",
    "data_loader.download_dataset()\n",
    "train_corpus, test = data_loader.get_dataset() #train_corpus is a flair Corpus containing train and dev\n",
    "train = train_corpus.train\n",
    "dev = train_corpus.dev\n",
    "\n",
    "print(f\"Train set type: {type(train)}\")\n",
    "print(f\"Test set type: {type(test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define experimentation object, which will be used for logging the experiments parameters, metrics and artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experimentation = MlflowExperimentation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlairNERModel(BaseModel):\n",
    "    def __init__(\n",
    "        self,\n",
    "        corpus: Corpus,\n",
    "        hidden_size: int = 256,\n",
    "        pooling: str = \"min\",\n",
    "        word_embeddings: str = \"glove\",\n",
    "        train_with_dev: bool = True,\n",
    "        max_epochs: int = 10,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        NER detector using the Flair NLP package.\n",
    "        Source: https://github.com/flairNLP/flair/blob/master/resources/docs/EXPERIMENTS.md\n",
    "        All class inputs (except for the corpus) are model hyper parameters.\n",
    "        They are then directed to the base class and get logged into the experiment logger\n",
    "        \"\"\"\n",
    "        self.tag_type = \"ner\"\n",
    "        self.tag_dictionary = None\n",
    "        self.tagger = None\n",
    "        self.embeddings = None\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.pooling = pooling\n",
    "        self.word_embeddings = word_embeddings\n",
    "        self.train_with_dev = train_with_dev\n",
    "        self.max_epochs = max_epochs\n",
    "\n",
    "        self.set_tagger_definition(corpus)\n",
    "\n",
    "        hyper_params = self.get_hyper_params(\n",
    "            hidden_size=hidden_size,\n",
    "            pooling=pooling,\n",
    "            word_embeddings=word_embeddings,\n",
    "            train_with_dev=train_with_dev,\n",
    "            max_epochs=max_epochs,\n",
    "        )\n",
    "\n",
    "        super().__init__(**hyper_params)\n",
    "\n",
    "    def fit(self, X, y=None) -> None:\n",
    "        # initialize trainer\n",
    "        trainer: ModelTrainer = ModelTrainer(self.tagger, X)\n",
    "\n",
    "        trainer.train(\n",
    "            \"models/taggers/flair-ner\",\n",
    "            train_with_dev=self.train_with_dev,\n",
    "            max_epochs=self.max_epochs,\n",
    "        )\n",
    "\n",
    "    def predict(self, X):\n",
    "        tagged_sentences = []\n",
    "        for sentence in tqdm(X):\n",
    "            self.tagger.predict(sentence)\n",
    "            tagged_sentences.append(sentence)\n",
    "        print(f\"Tagged {len(tagged_sentences)} sentences\")\n",
    "        return tagged_sentences\n",
    "\n",
    "    def get_hyper_params(self, **hyper_params):\n",
    "        basic_params = {\n",
    "            param_name: param_value\n",
    "            for (param_name, param_value) in self.tagger.__dict__.items()\n",
    "            if type(param_value) in (bool, float, int, str)\n",
    "        }\n",
    "        hyper_params.update(basic_params)\n",
    "        return hyper_params\n",
    "\n",
    "    def set_embeddings_definition(self):\n",
    "        \"\"\"\n",
    "        Sets the embedding layers used by this tagger\n",
    "        \"\"\"\n",
    "        # initialize embeddings\n",
    "        embedding_types: List[TokenEmbeddings] = [\n",
    "            # Word embeddings (default = GloVe)\n",
    "            WordEmbeddings(self.word_embeddings),\n",
    "            # contextual string embeddings, forward\n",
    "            PooledFlairEmbeddings(\"news-forward\", pooling=self.pooling),\n",
    "            # contextual string embeddings, backward\n",
    "            PooledFlairEmbeddings(\"news-backward\", pooling=self.pooling),\n",
    "        ]\n",
    "        self.embeddings: StackedEmbeddings = StackedEmbeddings(\n",
    "            embeddings=embedding_types\n",
    "        )\n",
    "\n",
    "    def set_tagger_definition(self, corpus: Corpus):\n",
    "        \"\"\"\n",
    "        Returns the definition of the Flair SequenceTagger (the full model)\n",
    "        :param corpus: Used only for setting the tag_dictionary\n",
    "        \"\"\"\n",
    "\n",
    "        if not self.embeddings:\n",
    "            self.set_embeddings_definition()\n",
    "        self.tag_dictionary = corpus.make_tag_dictionary(tag_type=self.tag_type)\n",
    "\n",
    "        tagger: SequenceTagger = SequenceTagger(\n",
    "            hidden_size=self.hidden_size,\n",
    "            embeddings=self.embeddings,\n",
    "            tag_dictionary=self.tag_dictionary,\n",
    "            tag_type=self.tag_type,\n",
    "            use_crf=False,\n",
    "        )\n",
    "        self.tagger = tagger\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FlairNERModel(corpus=train_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN=False\n",
    "\n",
    "if TRAIN:\n",
    "    model.fit(corpus=train_corpus)\n",
    "else:\n",
    "    # Simulate training has finished by downloading a pretrained model\n",
    "    model.tagger = SequenceTagger.load('ner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = NEREvaluator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_runner = ExperimentRunner(\n",
    "    model=model,\n",
    "    X_train=train,\n",
    "    X_test=test,\n",
    "    data_loader=data_loader,\n",
    "    log_experiment=True,\n",
    "    experiment_logger=experimentation,\n",
    "    evaluator=evaluator,\n",
    "    experiment_name=\"Experiment\",\n",
    "    data_scientist=\"Omri\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = experiment_runner.run()\n",
    "results = experiment_runner.evaluate()\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "PyCharm (ner_sample)",
   "language": "python",
   "name": "pycharm-e86bbb65"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}